{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5384615384615414\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "# Test with sample graph in Fig 2.b\n",
    "G = nx.Graph()\n",
    "nodes = [1, 2, 3, 4, 5]\n",
    "edges = [(1, 3), (3, 5), (3, 2), (3, 4), (2, 5), (2, 4)]\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "L = nx.laplacian_matrix(G).toarray()\n",
    "L_dagger = np.linalg.pinv(L)\n",
    "\n",
    "n = G.number_of_nodes()\n",
    "effective_resistance_sum = 0\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        b_xy = np.zeros(n)\n",
    "        b_xy[i] = 1\n",
    "        b_xy[j] = -1\n",
    "        effective_resistance = np.dot(np.dot(b_xy.T, L_dagger), b_xy)\n",
    "        if b_xy[1] and sum(b_xy) == 0:\n",
    "            effective_resistance_sum += effective_resistance\n",
    "            # print(b_xy, eff_edge)\n",
    "effective_resistance_sum = 2 * len(nodes)/effective_resistance_sum\n",
    "print(effective_resistance_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test when edge remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6775067750677507\n"
     ]
    }
   ],
   "source": [
    "# Test with sample graph in Fig 2.b\n",
    "G = nx.Graph()\n",
    "nodes = [1, 2, 3, 4, 5]\n",
    "edges = [(1, 3), (3, 5), (3, 2), (3, 4), (2, 5), (2, 4)]\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(edges)\n",
    "n = G.number_of_nodes()\n",
    "G.remove_edges_from([(2, 4), (2, 5)])\n",
    "L = nx.laplacian_matrix(G).toarray()\n",
    "L_dagger = np.linalg.pinv(L)\n",
    "effective_resistance_sum = 0\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        b_xy = np.zeros(n)\n",
    "        b_xy[i] = 1\n",
    "        b_xy[j] = -1\n",
    "        effective_resistance = np.dot(np.dot(b_xy.T, L_dagger), b_xy)\n",
    "        if b_xy[1]:\n",
    "            effective_resistance_sum += effective_resistance\n",
    "effective_resistance_sum = 2 * len(nodes)/effective_resistance_sum\n",
    "print(effective_resistance_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate information centrality by [45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "def compute_information_centrality_by_Laplacian(G: nx.Graph, node):\n",
    "    L = nx.laplacian_matrix(G).toarray()\n",
    "    n = G.number_of_nodes()\n",
    "    L_dagger = np.linalg.pinv(L)\n",
    "    effective_resistance_of_node = n * L_dagger[node][node] + np.trace(L_dagger)\n",
    "    information_centrality = n / effective_resistance_of_node\n",
    "    return information_centrality, effective_resistance_of_node\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with Fig.3(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified information centrality of node 2 in the original graph: 1.54\n",
      "Modified information centrality of node 2 after removing edges (2, 4) and (2, 5): 0.71\n",
      "Modified information centrality of node 2 after removing edges (2, 3) and (2, 4): 0.56\n"
     ]
    }
   ],
   "source": [
    "# Test with sample graph in Fig 2.b\n",
    "G = nx.Graph()\n",
    "nodes = [0,1,2,3,4]\n",
    "edges = [(0,2), (1,2), (1,3), (1, 4), (2, 3), (2, 4)]\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "# Compute the modified information centrality for node 2 in the original graph\n",
    "initial_centrality, initial_effective = compute_information_centrality_by_Laplacian(G, 1)\n",
    "print(f\"Modified information centrality of node 2 in the original graph: {initial_centrality:.2f}\")\n",
    "# print(f\"initial_effective: {initial_effective:.2f}\")\n",
    "\n",
    "# Remove edges (2, 4) and (2, 5), and compute the modified information centrality for node 2\n",
    "G_removed = G.copy()\n",
    "G_removed.remove_edges_from([(1, 3), (1, 4)])\n",
    "centrality_removed_23_25, _ = compute_information_centrality_by_Laplacian(G_removed, 1)\n",
    "print(f\"Modified information centrality of node 2 after removing edges (2, 4) and (2, 5): {centrality_removed_23_25:.2f}\")\n",
    "\n",
    "# Remove edges (2, 3) and (2, 4), and compute the modified information centrality for node 2\n",
    "G_removed = G.copy()\n",
    "G_removed.remove_edges_from([(1, 2), (1, 3)])\n",
    "centrality_removed_23_24, _ = compute_information_centrality_by_Laplacian(G_removed, 1)\n",
    "print(f\"Modified information centrality of node 2 after removing edges (2, 3) and (2, 4): {centrality_removed_23_24:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTIMUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def OPTIMUM(G:nx.Graph,T,k):\n",
    "    P = []\n",
    "    n = G.number_of_nodes()\n",
    "\n",
    "    L = nx.laplacian_matrix(G).toarray()\n",
    "    L_dagger = np.linalg.pinv(L)\n",
    "\n",
    "    for _ in range(k):\n",
    "        information_centrality_list = []\n",
    "        for e in G.edges():\n",
    "            information_centrality = 0\n",
    "            information_centrality_sum = 0\n",
    "            x, y = e\n",
    "            G_copy = G.copy()\n",
    "            G_copy.remove_edge(x, y)\n",
    "            L = nx.laplacian_matrix(G_copy).toarray()\n",
    "            L_dagger = np.linalg.pinv(L)\n",
    "            for v in T:\n",
    "                effective_resistance_of_node = n * L_dagger[v][v] + np.trace(L_dagger)\n",
    "                information_centrality = n / effective_resistance_of_node\n",
    "                information_centrality_sum += information_centrality\n",
    "            information_centrality_list.append((information_centrality_sum / k, e))\n",
    "        arg_min = min(information_centrality_list)\n",
    "        P.append(arg_min[1])\n",
    "        G.remove_edge(arg_min[1][0], arg_min[1][1])\n",
    "    return P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXACTSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EXACTSM(G:nx.Graph,T,k):\n",
    "    P = []\n",
    "    n = G.number_of_nodes()\n",
    "    L = nx.laplacian_matrix(G).toarray()\n",
    "    L_dagger = np.linalg.pinv(L)\n",
    "\n",
    "    for _ in range(k):\n",
    "        information_centrality_list = []\n",
    "        for e in G.edges():\n",
    "            information_centrality = 0\n",
    "            x, y = e\n",
    "            G_copy = G.copy()\n",
    "            G_copy.remove_edge(x, y)    \n",
    "            if nx.is_connected(G_copy):\n",
    "                b_e = np.zeros(n)\n",
    "                b_e[x] = 1\n",
    "                b_e[y] = -1\n",
    "                # Calculate a, b, and c as defined in Lemma VII.1\n",
    "                a = 1 - np.dot(b_e.T, np.dot(L_dagger, b_e))\n",
    "                b = np.dot(b_e.T, np.dot(np.dot(L_dagger, L_dagger), b_e))\n",
    "                L_dagger_b_e = np.dot(L_dagger, b_e)\n",
    "                for v in T:\n",
    "                    c = L_dagger_b_e[v] ** 2\n",
    "\n",
    "                    # Calculate numerator and denominator\n",
    "                    numerator = -(n * b + n**2 * c)\n",
    "                    term1 = n * a * L_dagger[v][v] + n * c\n",
    "                    term2 = a * np.trace(L_dagger) + b\n",
    "                    term3 = n * L_dagger[v][v] + np.trace(L_dagger)\n",
    "                    denominator = (term1 + term2) * term3\n",
    "\n",
    "                    # Calculate information centrality\n",
    "                    information_centrality += numerator / denominator\n",
    "\n",
    "            information_centrality_list.append((information_centrality, e))\n",
    "        arg_min = min(information_centrality_list)\n",
    "        P.append(arg_min[1])\n",
    "        G.remove_edge(arg_min[1][0], arg_min[1][1])\n",
    "        b_ei = np.zeros(n)\n",
    "        b_ei[arg_min[1][0]] = 1\n",
    "        b_ei[arg_min[1][1]] = -1\n",
    "        L_dagger += np.dot(np.dot(np.dot(L_dagger, b_ei), b_ei.T), L_dagger) / (1 - np.dot(np.dot(b_ei.T, L_dagger), b_ei))\n",
    "    return P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file to RAM\n",
    "# small graph: karate, polbooks, hamsterster, ca-GrQc\n",
    "with open('./polbooks.mtx', 'r') as file:\n",
    "    result = [(int(a) - 1, int(b) - 1) for a, b in (line.split() for line in file)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target nodes: [1, 21, 25, 30, 44, 63, 73, 79, 95, 102]\n",
      "Information centrality average of target nodes: 2.3384766618919075\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# Input to graph\n",
    "G = nx.Graph()\n",
    "edges = result\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "# Experiment set\n",
    "number_of_target_nodes = 10\n",
    "k = 10\n",
    "\n",
    "# Random sample\n",
    "target_nodes = [1, 21, 25, 30, 44, 63, 73, 79, 95, 102]\n",
    "# target_nodes = random.sample(list(G.nodes()), number_of_target_nodes)\n",
    "all_information = 0\n",
    "for i in target_nodes:\n",
    "    initial_centrality, initial_effective = compute_information_centrality_by_Laplacian(G, i)\n",
    "    # print(f\"Information centrality of node {i}: {initial_centrality:.2f}\")\n",
    "    all_information += initial_centrality\n",
    "print(f\"Target nodes: {target_nodes}\")\n",
    "print(f\"Information centrality average of target nodes: {all_information/number_of_target_nodes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST: Random select edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove random edges: [(73, 92), (19, 55), (27, 40), (74, 84), (58, 85), (88, 89), (75, 83), (102, 94), (30, 66), (12, 17)]\n",
      "Target nodes: [1, 21, 25, 30, 44, 63, 73, 79, 95, 102]\n",
      "Information centrality average of target nodes: 2.2503509813998326\n"
     ]
    }
   ],
   "source": [
    "G_copy = G.copy()\n",
    "random_edges = random.sample(list(G_copy.edges()), k)\n",
    "G_copy.remove_edges_from(random_edges)\n",
    "# Test\n",
    "all_information = 0\n",
    "for i in target_nodes:\n",
    "    initial_centrality, initial_effective = compute_information_centrality_by_Laplacian(G_copy, i)\n",
    "    all_information += initial_centrality\n",
    "print(f\"Remove random edges: {random_edges}\")\n",
    "print(f\"Target nodes: {target_nodes}\")\n",
    "print(f\"Information centrality average of target nodes: {all_information / number_of_target_nodes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST: OPTIMUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need remove edge: [(67, 103), (67, 104), (72, 92), (73, 92), (30, 67), (66, 67), (67, 64), (46, 102), (53, 76), (19, 77)]\n",
      "Target nodes: [1, 21, 25, 30, 44, 63, 73, 79, 95, 102]\n",
      "Information centrality average of target nodes: 1.8221472063961683\n"
     ]
    }
   ],
   "source": [
    "G_copy = G.copy()\n",
    "P = OPTIMUM(G_copy, target_nodes, k)\n",
    "print(\"Need remove edge:\", P)\n",
    "# Check if edge remove\n",
    "G_copy = G.copy()\n",
    "G_copy.remove_edges_from(P)\n",
    "# Test\n",
    "all_information = 0\n",
    "for i in target_nodes:\n",
    "    initial_centrality, initial_effective = compute_information_centrality_by_Laplacian(G_copy, i)\n",
    "    # print(f\"Information centrality of node {i}: {initial_centrality:.2f}\")\n",
    "    all_information += initial_centrality\n",
    "print(f\"Target nodes: {target_nodes}\")\n",
    "print(f\"Information centrality average of target nodes: {all_information / number_of_target_nodes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST: EXACTSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need remove edge: [(100, 98), (30, 79), (46, 102), (74, 79), (79, 91), (79, 100), (72, 79), (75, 79), (71, 79), (87, 98)]\n",
      "Target nodes: [1, 21, 25, 30, 44, 63, 73, 79, 95, 102]\n",
      "Information centrality average of target nodes: 2.22715799274928\n"
     ]
    }
   ],
   "source": [
    "G_copy = G.copy()\n",
    "P = EXACTSM(G_copy, target_nodes, k)\n",
    "print(\"Need remove edge:\", P)\n",
    "# Check if edge remove\n",
    "G_copy = G.copy()\n",
    "G_copy.remove_edges_from(P)\n",
    "# Test\n",
    "all_information = 0\n",
    "for i in target_nodes:\n",
    "    initial_centrality, initial_effective = compute_information_centrality_by_Laplacian(G_copy, i)\n",
    "    # print(f\"Information centrality of node {i}: {initial_centrality:.2f}\")\n",
    "    all_information += initial_centrality\n",
    "print(f\"Target nodes: {target_nodes}\")\n",
    "print(f\"Information centrality average of target nodes: {all_information / number_of_target_nodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need remove edge: [(104, 69), (104, 67), (28, 4), (72, 28), (102, 46), (95, 73), (95, 61), (95, 94), (102, 93), (76, 53)]\n",
      "Target nodes: [24, 26, 28, 32, 43, 44, 54, 95, 101, 104]\n",
      "Information centrality average of target nodes: 1.8667036248343578\n"
     ]
    }
   ],
   "source": [
    "G_copy = G.copy()\n",
    "target_nodes = [24, 26, 28, 32, 43, 44, 54, 95, 101, 104]\n",
    "P = [(104, 69), (104, 67), (28, 4), (72, 28), (102, 46), (95, 73), (95, 61), (95, 94), (102, 93), (76, 53)]\n",
    "print(\"Need remove edge:\", P)\n",
    "# Check if edge remove\n",
    "G_copy = G.copy()\n",
    "G_copy.remove_edges_from(P)\n",
    "# Test\n",
    "all_information = 0\n",
    "for i in target_nodes:\n",
    "    initial_centrality, initial_effective = compute_information_centrality_by_Laplacian(G_copy, i)\n",
    "    # print(f\"Information centrality of node {i}: {initial_centrality:.2f}\")\n",
    "    all_information += initial_centrality\n",
    "print(f\"Target nodes: {target_nodes}\")\n",
    "print(f\"Information centrality average of target nodes: {all_information / number_of_target_nodes}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
